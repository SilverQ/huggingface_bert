{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "bcc7a187",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'nltk.bleu_score'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Input \u001b[0;32mIn [54]\u001b[0m, in \u001b[0;36m<cell line: 16>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnltk\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m load\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnltk\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtranslate\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbleu_score\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mbleu\u001b[39;00m\n\u001b[0;32m---> 16\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnltk\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbleu_score\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'nltk.bleu_score'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import re\n",
    "import unicodedata\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from transformers import *\n",
    "import torch\n",
    "from tokenizers import *\n",
    "from datasets import *\n",
    "from sklearn.model_selection import train_test_split\n",
    "import nltk\n",
    "from nltk.data import load\n",
    "import nltk.translate.bleu_score as bleu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1ef6d9ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf57042d",
   "metadata": {},
   "source": [
    "### Data prepare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "147461de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_with_truncation(examples):\n",
    "    \"\"\"Mapping function to tokenize the sentences passed with truncation\"\"\"\n",
    "    return tokenizer(examples[\"text\"], truncation=True, padding=\"max_length\",\n",
    "                                     max_length=max_length, return_special_tokens_mask=True)\n",
    "\n",
    "def encode_without_truncation(examples):\n",
    "    \"\"\"Mapping function to tokenize the sentences passed without truncation\"\"\"\n",
    "    return tokenizer(examples[\"text\"], return_special_tokens_mask=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4b76d5ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the encode function will depend on the truncate_longer_samples variable\n",
    "# encode = encode_with_truncation if truncate_longer_samples else encode_without_truncation\n",
    "encode = encode_with_truncation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "09c84fb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:datasets.builder:Using custom data configuration default-b46801d40a7ba5f9\n",
      "WARNING:datasets.builder:Reusing dataset text (/home/hdh/.cache/huggingface/datasets/text/default-b46801d40a7ba5f9/0.0.0)\n"
     ]
    }
   ],
   "source": [
    "# dataset = Dataset.from_text('data/c09k_corpus.txt')\n",
    "dataset = Dataset.from_text('data/c09k_pre_test.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "63571d47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset['text'][:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ffd7f5e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "examples = ['본 발명에 따르면, 폴리로탁산 모노머의 우수한 기계 특성을 유지하면서, 생산성이 높고, 고품질의 재료를 높은 수율로 제조할 수 있는 폴리로탁산 모노머를 제공할 수 있다.',\n",
    "'폴리아미드 섬유 또는 폴리우레탄 섬유로부터 되는 섬유(X)와 폴리오레핀(polyolefin) 수지와 포토 크로믹 재료를 함유 하는 섬유(Y)와 하지만 서로 꼼 합쳐진 것인 스타킹용 포토 크로믹 섬유',\n",
    "'본 발명은 칼라표시장치용 광선택 흡광제, 이를 포함하는 코팅제 및 상기 코팅제로 제조된 필터를 제공한다.상기 광선택 흡광제는 테트라아자포피린 유도체의 이합체를 포함한다',\n",
    "'상기한 목적을 달성하기 위하여 본 발명은 나노 세공의 다공성 육방정계의 실리카 분체내의 실리콘 일부가 전이금속으로 치환되고, 나노 세공내에 금속 산화물이 나노 크기로 담지된 복합분체를 제공한다']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "182a5e90",
   "metadata": {},
   "outputs": [],
   "source": [
    "def masking_ex(text):\n",
    "    text = text.split(' ')\n",
    "    length = len(text)\n",
    "    mask_ind = np.random.randint(length)\n",
    "    text[mask_ind] = '[MASK]'\n",
    "    text = ' '.join(text)\n",
    "#         print(length, result)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c84a0fa8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "본 발명에 따르면, 폴리로탁산 모노머의 우수한 기계 특성을 유지하면서, 생산성이 높고, 고품질의 재료를 [MASK] 수율로 제조할 수 있는 폴리로탁산 모노머를 제공할 수 있다.\n",
      "폴리아미드 섬유 또는 폴리우레탄 섬유로부터 되는 섬유(X)와 폴리오레핀(polyolefin) 수지와 포토 크로믹 재료를 함유 하는 [MASK] 하지만 서로 꼼 합쳐진 것인 스타킹용\n",
      "본 [MASK] 칼라표시장치용 광선택 흡광제, 이를 포함하는 코팅제 및 상기 코팅제로 제조된 필터를 제공한다.상기 광선택 흡광제는 테트라아자포피린 유도체의 이합체를 포함한다\n",
      "상기한 목적을 달성하기 위하여 본 발명은 나노 세공의 다공성 육방정계의 실리카 분체내의 실리콘 일부가 전이금속으로 [MASK] 나노 세공내에 금속 산화물이 나노 크기로 담지된 복합분\n"
     ]
    }
   ],
   "source": [
    "masked_sample = [masking_ex(text[:100]) for text in examples]\n",
    "for item in masked_sample:\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ffafc2a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = [['c09k_pretrained_bert', 'checkpoint-1500'],\n",
    "             ['c09k_pretrained_bert', 'checkpoint-2880'],\n",
    "             ['c09k_pretrained_bert', 'checkpoint-4500'],\n",
    "             ['c09k_pretrained_bert', 'checkpoint-6000'],\n",
    "             ['c09k_pretrained_bert', 'checkpoint-7500']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ce6e2b51",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_load(path):\n",
    "    # load the model checkpoint\n",
    "    model = BertForMaskedLM.from_pretrained(os.path.join(path[0], path[1]))\n",
    "    # load the tokenizer\n",
    "    tokenizer = BertTokenizerFast.from_pretrained(path[0])\n",
    "    return model, tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "efd8f6e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['c09k_pretrained_bert', 'checkpoint-1500']"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_path[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "0e55c9c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file c09k_pretrained_bert/checkpoint-1500/config.json\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"c09k_pretrained_bert/checkpoint-4320\",\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 64,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.22.0.dev0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 8000\n",
      "}\n",
      "\n",
      "loading weights file c09k_pretrained_bert/checkpoint-1500/pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing BertForMaskedLM.\n",
      "\n",
      "All the weights of BertForMaskedLM were initialized from the model checkpoint at c09k_pretrained_bert/checkpoint-1500.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForMaskedLM for predictions without further training.\n",
      "loading file vocab.txt\n",
      "loading file tokenizer.json\n",
      "loading file added_tokens.json\n",
      "loading file special_tokens_map.json\n",
      "loading file tokenizer_config.json\n",
      "loading configuration file c09k_pretrained_bert/config.json\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"c09k_pretrained_bert\",\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"cls_token\": \"[CLS]\",\n",
      "  \"do_lower_case\": true,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"mask_token\": \"[MASK]\",\n",
      "  \"max_len\": 512,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_max_length\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token\": \"[PAD]\",\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"sep_token\": \"[SEP]\",\n",
      "  \"transformers_version\": \"4.22.0.dev0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"unk_token\": \"[UNK]\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading configuration file c09k_pretrained_bert/checkpoint-2880/config.json\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"c09k_pretrained_bert/checkpoint-4320\",\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 64,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.22.0.dev0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 8000\n",
      "}\n",
      "\n",
      "loading weights file c09k_pretrained_bert/checkpoint-2880/pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocab_file vocab.txt\n",
      "tokenizer_file tokenizer.json\n",
      "added_tokens_file added_tokens.json\n",
      "special_tokens_map_file special_tokens_map.json\n",
      "tokenizer_config_file tokenizer_config.json\n",
      "본 발명에 따르면, 폴리로탁산 모노머의 우수한 기계 특성을 유지하면서, 생산성이 높고, 고품질의 재료를 얻을 수율로 제조할 수 있는 폴리로탁산 모노머를 제공할 수 있다., confidence: 0.1457536369562149\n",
      "본 발명에 따르면, 폴리로탁산 모노머의 우수한 기계 특성을 유지하면서, 생산성이 높고, 고품질의 재료를 제조할 수율로 제조할 수 있는 폴리로탁산 모노머를 제공할 수 있다., confidence: 0.050306208431720734\n",
      "본 발명에 따르면, 폴리로탁산 모노머의 우수한 기계 특성을 유지하면서, 생산성이 높고, 고품질의 재료를할 수율로 제조할 수 있는 폴리로탁산 모노머를 제공할 수 있다., confidence: 0.04066529870033264\n",
      "본 발명에 따르면, 폴리로탁산 모노머의 우수한 기계 특성을 유지하면서, 생산성이 높고, 고품질의 재료를 제공할 수율로 제조할 수 있는 폴리로탁산 모노머를 제공할 수 있다., confidence: 0.03267392888665199\n",
      "본 발명에 따르면, 폴리로탁산 모노머의 우수한 기계 특성을 유지하면서, 생산성이 높고, 고품질의 재료를 있는 수율로 제조할 수 있는 폴리로탁산 모노머를 제공할 수 있다., confidence: 0.029196813702583313\n",
      "폴리아미드 섬유 또는 폴리우레탄 섬유로부터 되는 섬유 ( x ) 와 폴리오레핀 ( polyolefin ) 수지와 포토 크로믹 재료를 함유 하는 전기 하지만 서로 꼼 합쳐진 것인 스타킹용, confidence: 0.05990314111113548\n",
      "폴리아미드 섬유 또는 폴리우레탄 섬유로부터 되는 섬유 ( x ) 와 폴리오레핀 ( polyolefin ) 수지와 포토 크로믹 재료를 함유 하는, 하지만 서로 꼼 합쳐진 것인 스타킹용, confidence: 0.05786002054810524\n",
      "폴리아미드 섬유 또는 폴리우레탄 섬유로부터 되는 섬유 ( x ) 와 폴리오레핀 ( polyolefin ) 수지와 포토 크로믹 재료를 함유 하는 해 하지만 서로 꼼 합쳐진 것인 스타킹용, confidence: 0.05349906533956528\n",
      "폴리아미드 섬유 또는 폴리우레탄 섬유로부터 되는 섬유 ( x ) 와 폴리오레핀 ( polyolefin ) 수지와 포토 크로믹 재료를 함유 하는. 하지만 서로 꼼 합쳐진 것인 스타킹용, confidence: 0.04648566618561745\n",
      "폴리아미드 섬유 또는 폴리우레탄 섬유로부터 되는 섬유 ( x ) 와 폴리오레핀 ( polyolefin ) 수지와 포토 크로믹 재료를 함유 하는 청구항 하지만 서로 꼼 합쳐진 것인 스타킹용, confidence: 0.03205234557390213\n",
      "본 발명의 칼라표시장치용 광선택 흡광제, 이를 포함하는 코팅제 및 상기 코팅제로 제조된 필터를 제공한다. 상기 광선택 흡광제는 테트라아자포피린 유도체의 이합체를 포함한다, confidence: 0.6228998303413391\n",
      "본 발명은 칼라표시장치용 광선택 흡광제, 이를 포함하는 코팅제 및 상기 코팅제로 제조된 필터를 제공한다. 상기 광선택 흡광제는 테트라아자포피린 유도체의 이합체를 포함한다, confidence: 0.2931271195411682\n",
      "본 발명에 칼라표시장치용 광선택 흡광제, 이를 포함하는 코팅제 및 상기 코팅제로 제조된 필터를 제공한다. 상기 광선택 흡광제는 테트라아자포피린 유도체의 이합체를 포함한다, confidence: 0.019478758797049522\n",
      "본 출원의 칼라표시장치용 광선택 흡광제, 이를 포함하는 코팅제 및 상기 코팅제로 제조된 필터를 제공한다. 상기 광선택 흡광제는 테트라아자포피린 유도체의 이합체를 포함한다, confidence: 0.003032290143892169\n",
      "본 출원은 칼라표시장치용 광선택 흡광제, 이를 포함하는 코팅제 및 상기 코팅제로 제조된 필터를 제공한다. 상기 광선택 흡광제는 테트라아자포피린 유도체의 이합체를 포함한다, confidence: 0.0027612014673650265\n",
      "상기한 목적을 달성하기 위하여 본 발명은 나노 세공의 다공성 육방정계의 실리카 분체내의 실리콘 일부가 전이금속으로 나노 나노 세공내에 금속 산화물이 나노 크기로 담지된 복합분, confidence: 0.0944746732711792\n",
      "상기한 목적을 달성하기 위하여 본 발명은 나노 세공의 다공성 육방정계의 실리카 분체내의 실리콘 일부가 전이금속으로 금속 나노 세공내에 금속 산화물이 나노 크기로 담지된 복합분, confidence: 0.05669058859348297\n",
      "상기한 목적을 달성하기 위하여 본 발명은 나노 세공의 다공성 육방정계의 실리카 분체내의 실리콘 일부가 전이금속으로 산화물 나노 세공내에 금속 산화물이 나노 크기로 담지된 복합분, confidence: 0.03151066228747368\n",
      "상기한 목적을 달성하기 위하여 본 발명은 나노 세공의 다공성 육방정계의 실리카 분체내의 실리콘 일부가 전이금속으로, 나노 세공내에 금속 산화물이 나노 크기로 담지된 복합분, confidence: 0.017397204414010048\n",
      "상기한 목적을 달성하기 위하여 본 발명은 나노 세공의 다공성 육방정계의 실리카 분체내의 실리콘 일부가 전이금속으로 하는 나노 세공내에 금속 산화물이 나노 크기로 담지된 복합분, confidence: 0.01309890765696764\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint weights were used when initializing BertForMaskedLM.\n",
      "\n",
      "All the weights of BertForMaskedLM were initialized from the model checkpoint at c09k_pretrained_bert/checkpoint-2880.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForMaskedLM for predictions without further training.\n",
      "loading file vocab.txt\n",
      "loading file tokenizer.json\n",
      "loading file added_tokens.json\n",
      "loading file special_tokens_map.json\n",
      "loading file tokenizer_config.json\n",
      "loading configuration file c09k_pretrained_bert/config.json\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"c09k_pretrained_bert\",\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"cls_token\": \"[CLS]\",\n",
      "  \"do_lower_case\": true,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"mask_token\": \"[MASK]\",\n",
      "  \"max_len\": 512,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_max_length\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token\": \"[PAD]\",\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"sep_token\": \"[SEP]\",\n",
      "  \"transformers_version\": \"4.22.0.dev0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"unk_token\": \"[UNK]\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading configuration file c09k_pretrained_bert/checkpoint-4500/config.json\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"c09k_pretrained_bert/checkpoint-4320\",\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 64,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.22.0.dev0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 8000\n",
      "}\n",
      "\n",
      "loading weights file c09k_pretrained_bert/checkpoint-4500/pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocab_file vocab.txt\n",
      "tokenizer_file tokenizer.json\n",
      "added_tokens_file added_tokens.json\n",
      "special_tokens_map_file special_tokens_map.json\n",
      "tokenizer_config_file tokenizer_config.json\n",
      "본 발명에 따르면, 폴리로탁산 모노머의 우수한 기계 특성을 유지하면서, 생산성이 높고, 고품질의 재료를 얻을 수율로 제조할 수 있는 폴리로탁산 모노머를 제공할 수 있다., confidence: 0.24339978396892548\n",
      "본 발명에 따르면, 폴리로탁산 모노머의 우수한 기계 특성을 유지하면서, 생산성이 높고, 고품질의 재료를 제조할 수율로 제조할 수 있는 폴리로탁산 모노머를 제공할 수 있다., confidence: 0.09570968151092529\n",
      "본 발명에 따르면, 폴리로탁산 모노머의 우수한 기계 특성을 유지하면서, 생산성이 높고, 고품질의 재료를 제공할 수율로 제조할 수 있는 폴리로탁산 모노머를 제공할 수 있다., confidence: 0.06419500708580017\n",
      "본 발명에 따르면, 폴리로탁산 모노머의 우수한 기계 특성을 유지하면서, 생산성이 높고, 고품질의 재료를할 수율로 제조할 수 있는 폴리로탁산 모노머를 제공할 수 있다., confidence: 0.06376192718744278\n",
      "본 발명에 따르면, 폴리로탁산 모노머의 우수한 기계 특성을 유지하면서, 생산성이 높고, 고품질의 재료를 형성할 수율로 제조할 수 있는 폴리로탁산 모노머를 제공할 수 있다., confidence: 0.039592865854501724\n",
      "폴리아미드 섬유 또는 폴리우레탄 섬유로부터 되는 섬유 ( x ) 와 폴리오레핀 ( polyolefin ) 수지와 포토 크로믹 재료를 함유 하는, 하지만 서로 꼼 합쳐진 것인 스타킹용, confidence: 0.07211979478597641\n",
      "폴리아미드 섬유 또는 폴리우레탄 섬유로부터 되는 섬유 ( x ) 와 폴리오레핀 ( polyolefin ) 수지와 포토 크로믹 재료를 함유 하는 전기 하지만 서로 꼼 합쳐진 것인 스타킹용, confidence: 0.05884794890880585\n",
      "폴리아미드 섬유 또는 폴리우레탄 섬유로부터 되는 섬유 ( x ) 와 폴리오레핀 ( polyolefin ) 수지와 포토 크로믹 재료를 함유 하는 해 하지만 서로 꼼 합쳐진 것인 스타킹용, confidence: 0.04377337172627449\n",
      "폴리아미드 섬유 또는 폴리우레탄 섬유로부터 되는 섬유 ( x ) 와 폴리오레핀 ( polyolefin ) 수지와 포토 크로믹 재료를 함유 하는 청구항 하지만 서로 꼼 합쳐진 것인 스타킹용, confidence: 0.03935902565717697\n",
      "폴리아미드 섬유 또는 폴리우레탄 섬유로부터 되는 섬유 ( x ) 와 폴리오레핀 ( polyolefin ) 수지와 포토 크로믹 재료를 함유 하는 폴리 하지만 서로 꼼 합쳐진 것인 스타킹용, confidence: 0.017113639041781425\n",
      "본 발명의 칼라표시장치용 광선택 흡광제, 이를 포함하는 코팅제 및 상기 코팅제로 제조된 필터를 제공한다. 상기 광선택 흡광제는 테트라아자포피린 유도체의 이합체를 포함한다, confidence: 0.559077262878418\n",
      "본 발명은 칼라표시장치용 광선택 흡광제, 이를 포함하는 코팅제 및 상기 코팅제로 제조된 필터를 제공한다. 상기 광선택 흡광제는 테트라아자포피린 유도체의 이합체를 포함한다, confidence: 0.3387771546840668\n",
      "본 발명에 칼라표시장치용 광선택 흡광제, 이를 포함하는 코팅제 및 상기 코팅제로 제조된 필터를 제공한다. 상기 광선택 흡광제는 테트라아자포피린 유도체의 이합체를 포함한다, confidence: 0.018444720655679703\n",
      "본 출원은 칼라표시장치용 광선택 흡광제, 이를 포함하는 코팅제 및 상기 코팅제로 제조된 필터를 제공한다. 상기 광선택 흡광제는 테트라아자포피린 유도체의 이합체를 포함한다, confidence: 0.007864254526793957\n",
      "본 출원의 칼라표시장치용 광선택 흡광제, 이를 포함하는 코팅제 및 상기 코팅제로 제조된 필터를 제공한다. 상기 광선택 흡광제는 테트라아자포피린 유도체의 이합체를 포함한다, confidence: 0.007086289115250111\n",
      "상기한 목적을 달성하기 위하여 본 발명은 나노 세공의 다공성 육방정계의 실리카 분체내의 실리콘 일부가 전이금속으로, 나노 세공내에 금속 산화물이 나노 크기로 담지된 복합분, confidence: 0.07176633924245834\n",
      "상기한 목적을 달성하기 위하여 본 발명은 나노 세공의 다공성 육방정계의 실리카 분체내의 실리콘 일부가 전이금속으로 하는 나노 세공내에 금속 산화물이 나노 크기로 담지된 복합분, confidence: 0.06368279457092285\n",
      "상기한 목적을 달성하기 위하여 본 발명은 나노 세공의 다공성 육방정계의 실리카 분체내의 실리콘 일부가 전이금속으로 나노 나노 세공내에 금속 산화물이 나노 크기로 담지된 복합분, confidence: 0.06206335127353668\n",
      "상기한 목적을 달성하기 위하여 본 발명은 나노 세공의 다공성 육방정계의 실리카 분체내의 실리콘 일부가 전이금속으로 금속 나노 세공내에 금속 산화물이 나노 크기로 담지된 복합분, confidence: 0.03047446720302105\n",
      "상기한 목적을 달성하기 위하여 본 발명은 나노 세공의 다공성 육방정계의 실리카 분체내의 실리콘 일부가 전이금속으로 가지는 나노 세공내에 금속 산화물이 나노 크기로 담지된 복합분, confidence: 0.02477896772325039\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint weights were used when initializing BertForMaskedLM.\n",
      "\n",
      "All the weights of BertForMaskedLM were initialized from the model checkpoint at c09k_pretrained_bert/checkpoint-4500.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForMaskedLM for predictions without further training.\n",
      "loading file vocab.txt\n",
      "loading file tokenizer.json\n",
      "loading file added_tokens.json\n",
      "loading file special_tokens_map.json\n",
      "loading file tokenizer_config.json\n",
      "loading configuration file c09k_pretrained_bert/config.json\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"c09k_pretrained_bert\",\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"cls_token\": \"[CLS]\",\n",
      "  \"do_lower_case\": true,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"mask_token\": \"[MASK]\",\n",
      "  \"max_len\": 512,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_max_length\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token\": \"[PAD]\",\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"sep_token\": \"[SEP]\",\n",
      "  \"transformers_version\": \"4.22.0.dev0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"unk_token\": \"[UNK]\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading configuration file c09k_pretrained_bert/checkpoint-6000/config.json\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"c09k_pretrained_bert/checkpoint-4320\",\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 64,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.22.0.dev0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 8000\n",
      "}\n",
      "\n",
      "loading weights file c09k_pretrained_bert/checkpoint-6000/pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocab_file vocab.txt\n",
      "tokenizer_file tokenizer.json\n",
      "added_tokens_file added_tokens.json\n",
      "special_tokens_map_file special_tokens_map.json\n",
      "tokenizer_config_file tokenizer_config.json\n",
      "본 발명에 따르면, 폴리로탁산 모노머의 우수한 기계 특성을 유지하면서, 생산성이 높고, 고품질의 재료를 얻을 수율로 제조할 수 있는 폴리로탁산 모노머를 제공할 수 있다., confidence: 0.28728723526000977\n",
      "본 발명에 따르면, 폴리로탁산 모노머의 우수한 기계 특성을 유지하면서, 생산성이 높고, 고품질의 재료를 제조할 수율로 제조할 수 있는 폴리로탁산 모노머를 제공할 수 있다., confidence: 0.1961677074432373\n",
      "본 발명에 따르면, 폴리로탁산 모노머의 우수한 기계 특성을 유지하면서, 생산성이 높고, 고품질의 재료를 제공할 수율로 제조할 수 있는 폴리로탁산 모노머를 제공할 수 있다., confidence: 0.09082634747028351\n",
      "본 발명에 따르면, 폴리로탁산 모노머의 우수한 기계 특성을 유지하면서, 생산성이 높고, 고품질의 재료를 형성할 수율로 제조할 수 있는 폴리로탁산 모노머를 제공할 수 있다., confidence: 0.0685279443860054\n",
      "본 발명에 따르면, 폴리로탁산 모노머의 우수한 기계 특성을 유지하면서, 생산성이 높고, 고품질의 재료를 사용할 수율로 제조할 수 있는 폴리로탁산 모노머를 제공할 수 있다., confidence: 0.022523202002048492\n",
      "폴리아미드 섬유 또는 폴리우레탄 섬유로부터 되는 섬유 ( x ) 와 폴리오레핀 ( polyolefin ) 수지와 포토 크로믹 재료를 함유 하는 섬유 하지만 서로 꼼 합쳐진 것인 스타킹용, confidence: 0.29809021949768066\n",
      "폴리아미드 섬유 또는 폴리우레탄 섬유로부터 되는 섬유 ( x ) 와 폴리오레핀 ( polyolefin ) 수지와 포토 크로믹 재료를 함유 하는 것 하지만 서로 꼼 합쳐진 것인 스타킹용, confidence: 0.029573507606983185\n",
      "폴리아미드 섬유 또는 폴리우레탄 섬유로부터 되는 섬유 ( x ) 와 폴리오레핀 ( polyolefin ) 수지와 포토 크로믹 재료를 함유 하는 매트릭스 하지만 서로 꼼 합쳐진 것인 스타킹용, confidence: 0.023508990183472633\n",
      "폴리아미드 섬유 또는 폴리우레탄 섬유로부터 되는 섬유 ( x ) 와 폴리오레핀 ( polyolefin ) 수지와 포토 크로믹 재료를 함유 하는 것으로 하지만 서로 꼼 합쳐진 것인 스타킹용, confidence: 0.019614454358816147\n",
      "폴리아미드 섬유 또는 폴리우레탄 섬유로부터 되는 섬유 ( x ) 와 폴리오레핀 ( polyolefin ) 수지와 포토 크로믹 재료를 함유 하는 적층체 하지만 서로 꼼 합쳐진 것인 스타킹용, confidence: 0.01565469615161419\n",
      "본 발명의 칼라표시장치용 광선택 흡광제, 이를 포함하는 코팅제 및 상기 코팅제로 제조된 필터를 제공한다. 상기 광선택 흡광제는 테트라아자포피린 유도체의 이합체를 포함한다, confidence: 0.6655505895614624\n",
      "본 발명은 칼라표시장치용 광선택 흡광제, 이를 포함하는 코팅제 및 상기 코팅제로 제조된 필터를 제공한다. 상기 광선택 흡광제는 테트라아자포피린 유도체의 이합체를 포함한다, confidence: 0.28167617321014404\n",
      "본 출원은 칼라표시장치용 광선택 흡광제, 이를 포함하는 코팅제 및 상기 코팅제로 제조된 필터를 제공한다. 상기 광선택 흡광제는 테트라아자포피린 유도체의 이합체를 포함한다, confidence: 0.0067706117406487465\n",
      "본 출원의 칼라표시장치용 광선택 흡광제, 이를 포함하는 코팅제 및 상기 코팅제로 제조된 필터를 제공한다. 상기 광선택 흡광제는 테트라아자포피린 유도체의 이합체를 포함한다, confidence: 0.005796925164759159\n",
      "본 발명에 칼라표시장치용 광선택 흡광제, 이를 포함하는 코팅제 및 상기 코팅제로 제조된 필터를 제공한다. 상기 광선택 흡광제는 테트라아자포피린 유도체의 이합체를 포함한다, confidence: 0.005594965070486069\n",
      "상기한 목적을 달성하기 위하여 본 발명은 나노 세공의 다공성 육방정계의 실리카 분체내의 실리콘 일부가 전이금속으로, 나노 세공내에 금속 산화물이 나노 크기로 담지된 복합분, confidence: 0.09284592419862747\n",
      "상기한 목적을 달성하기 위하여 본 발명은 나노 세공의 다공성 육방정계의 실리카 분체내의 실리콘 일부가 전이금속으로 이루어진 나노 세공내에 금속 산화물이 나노 크기로 담지된 복합분, confidence: 0.03835839778184891\n",
      "상기한 목적을 달성하기 위하여 본 발명은 나노 세공의 다공성 육방정계의 실리카 분체내의 실리콘 일부가 전이금속으로 하는 나노 세공내에 금속 산화물이 나노 크기로 담지된 복합분, confidence: 0.035037294030189514\n",
      "상기한 목적을 달성하기 위하여 본 발명은 나노 세공의 다공성 육방정계의 실리카 분체내의 실리콘 일부가 전이금속으로 구성되는 나노 세공내에 금속 산화물이 나노 크기로 담지된 복합분, confidence: 0.03131166100502014\n",
      "상기한 목적을 달성하기 위하여 본 발명은 나노 세공의 다공성 육방정계의 실리카 분체내의 실리콘 일부가 전이금속으로 구성된 나노 세공내에 금속 산화물이 나노 크기로 담지된 복합분, confidence: 0.027415119111537933\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint weights were used when initializing BertForMaskedLM.\n",
      "\n",
      "All the weights of BertForMaskedLM were initialized from the model checkpoint at c09k_pretrained_bert/checkpoint-6000.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForMaskedLM for predictions without further training.\n",
      "loading file vocab.txt\n",
      "loading file tokenizer.json\n",
      "loading file added_tokens.json\n",
      "loading file special_tokens_map.json\n",
      "loading file tokenizer_config.json\n",
      "loading configuration file c09k_pretrained_bert/config.json\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"c09k_pretrained_bert\",\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"cls_token\": \"[CLS]\",\n",
      "  \"do_lower_case\": true,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"mask_token\": \"[MASK]\",\n",
      "  \"max_len\": 512,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_max_length\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token\": \"[PAD]\",\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"sep_token\": \"[SEP]\",\n",
      "  \"transformers_version\": \"4.22.0.dev0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"unk_token\": \"[UNK]\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading configuration file c09k_pretrained_bert/checkpoint-7500/config.json\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"c09k_pretrained_bert/checkpoint-4320\",\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 64,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.22.0.dev0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 8000\n",
      "}\n",
      "\n",
      "loading weights file c09k_pretrained_bert/checkpoint-7500/pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocab_file vocab.txt\n",
      "tokenizer_file tokenizer.json\n",
      "added_tokens_file added_tokens.json\n",
      "special_tokens_map_file special_tokens_map.json\n",
      "tokenizer_config_file tokenizer_config.json\n",
      "본 발명에 따르면, 폴리로탁산 모노머의 우수한 기계 특성을 유지하면서, 생산성이 높고, 고품질의 재료를 얻을 수율로 제조할 수 있는 폴리로탁산 모노머를 제공할 수 있다., confidence: 0.32060763239860535\n",
      "본 발명에 따르면, 폴리로탁산 모노머의 우수한 기계 특성을 유지하면서, 생산성이 높고, 고품질의 재료를 제조할 수율로 제조할 수 있는 폴리로탁산 모노머를 제공할 수 있다., confidence: 0.19089171290397644\n",
      "본 발명에 따르면, 폴리로탁산 모노머의 우수한 기계 특성을 유지하면서, 생산성이 높고, 고품질의 재료를 제공할 수율로 제조할 수 있는 폴리로탁산 모노머를 제공할 수 있다., confidence: 0.1143389567732811\n",
      "본 발명에 따르면, 폴리로탁산 모노머의 우수한 기계 특성을 유지하면서, 생산성이 높고, 고품질의 재료를 형성할 수율로 제조할 수 있는 폴리로탁산 모노머를 제공할 수 있다., confidence: 0.06491196900606155\n",
      "본 발명에 따르면, 폴리로탁산 모노머의 우수한 기계 특성을 유지하면서, 생산성이 높고, 고품질의 재료를 사용할 수율로 제조할 수 있는 폴리로탁산 모노머를 제공할 수 있다., confidence: 0.026097513735294342\n",
      "폴리아미드 섬유 또는 폴리우레탄 섬유로부터 되는 섬유 ( x ) 와 폴리오레핀 ( polyolefin ) 수지와 포토 크로믹 재료를 함유 하는 섬유 하지만 서로 꼼 합쳐진 것인 스타킹용, confidence: 0.5615658760070801\n",
      "폴리아미드 섬유 또는 폴리우레탄 섬유로부터 되는 섬유 ( x ) 와 폴리오레핀 ( polyolefin ) 수지와 포토 크로믹 재료를 함유 하는 것 하지만 서로 꼼 합쳐진 것인 스타킹용, confidence: 0.014945085160434246\n",
      "폴리아미드 섬유 또는 폴리우레탄 섬유로부터 되는 섬유 ( x ) 와 폴리오레핀 ( polyolefin ) 수지와 포토 크로믹 재료를 함유 하는 것으로 하지만 서로 꼼 합쳐진 것인 스타킹용, confidence: 0.011120270937681198\n",
      "폴리아미드 섬유 또는 폴리우레탄 섬유로부터 되는 섬유 ( x ) 와 폴리오레핀 ( polyolefin ) 수지와 포토 크로믹 재료를 함유 하는 매트릭스 하지만 서로 꼼 합쳐진 것인 스타킹용, confidence: 0.010994757525622845\n",
      "폴리아미드 섬유 또는 폴리우레탄 섬유로부터 되는 섬유 ( x ) 와 폴리오레핀 ( polyolefin ) 수지와 포토 크로믹 재료를 함유 하는 적층체 하지만 서로 꼼 합쳐진 것인 스타킹용, confidence: 0.009954950772225857\n",
      "본 발명의 칼라표시장치용 광선택 흡광제, 이를 포함하는 코팅제 및 상기 코팅제로 제조된 필터를 제공한다. 상기 광선택 흡광제는 테트라아자포피린 유도체의 이합체를 포함한다, confidence: 0.5656404495239258\n",
      "본 발명은 칼라표시장치용 광선택 흡광제, 이를 포함하는 코팅제 및 상기 코팅제로 제조된 필터를 제공한다. 상기 광선택 흡광제는 테트라아자포피린 유도체의 이합체를 포함한다, confidence: 0.38279497623443604\n",
      "본 출원은 칼라표시장치용 광선택 흡광제, 이를 포함하는 코팅제 및 상기 코팅제로 제조된 필터를 제공한다. 상기 광선택 흡광제는 테트라아자포피린 유도체의 이합체를 포함한다, confidence: 0.006781001575291157\n",
      "본 출원의 칼라표시장치용 광선택 흡광제, 이를 포함하는 코팅제 및 상기 코팅제로 제조된 필터를 제공한다. 상기 광선택 흡광제는 테트라아자포피린 유도체의 이합체를 포함한다, confidence: 0.00515741528943181\n",
      "본 발명에 칼라표시장치용 광선택 흡광제, 이를 포함하는 코팅제 및 상기 코팅제로 제조된 필터를 제공한다. 상기 광선택 흡광제는 테트라아자포피린 유도체의 이합체를 포함한다, confidence: 0.004920827224850655\n",
      "상기한 목적을 달성하기 위하여 본 발명은 나노 세공의 다공성 육방정계의 실리카 분체내의 실리콘 일부가 전이금속으로, 나노 세공내에 금속 산화물이 나노 크기로 담지된 복합분, confidence: 0.12166652083396912\n",
      "상기한 목적을 달성하기 위하여 본 발명은 나노 세공의 다공성 육방정계의 실리카 분체내의 실리콘 일부가 전이금속으로 나노 나노 세공내에 금속 산화물이 나노 크기로 담지된 복합분, confidence: 0.028967808932065964\n",
      "상기한 목적을 달성하기 위하여 본 발명은 나노 세공의 다공성 육방정계의 실리카 분체내의 실리콘 일부가 전이금속으로 하는 나노 세공내에 금속 산화물이 나노 크기로 담지된 복합분, confidence: 0.026279905810952187\n",
      "상기한 목적을 달성하기 위하여 본 발명은 나노 세공의 다공성 육방정계의 실리카 분체내의 실리콘 일부가 전이금속으로 금속 나노 세공내에 금속 산화물이 나노 크기로 담지된 복합분, confidence: 0.02621069923043251\n",
      "상기한 목적을 달성하기 위하여 본 발명은 나노 세공의 다공성 육방정계의 실리카 분체내의 실리콘 일부가 전이금속으로 복합 나노 세공내에 금속 산화물이 나노 크기로 담지된 복합분, confidence: 0.022455448284745216\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint weights were used when initializing BertForMaskedLM.\n",
      "\n",
      "All the weights of BertForMaskedLM were initialized from the model checkpoint at c09k_pretrained_bert/checkpoint-7500.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForMaskedLM for predictions without further training.\n",
      "loading file vocab.txt\n",
      "loading file tokenizer.json\n",
      "loading file added_tokens.json\n",
      "loading file special_tokens_map.json\n",
      "loading file tokenizer_config.json\n",
      "loading configuration file c09k_pretrained_bert/config.json\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"c09k_pretrained_bert\",\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"cls_token\": \"[CLS]\",\n",
      "  \"do_lower_case\": true,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"mask_token\": \"[MASK]\",\n",
      "  \"max_len\": 512,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_max_length\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token\": \"[PAD]\",\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"sep_token\": \"[SEP]\",\n",
      "  \"transformers_version\": \"4.22.0.dev0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"unk_token\": \"[UNK]\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocab_file vocab.txt\n",
      "tokenizer_file tokenizer.json\n",
      "added_tokens_file added_tokens.json\n",
      "special_tokens_map_file special_tokens_map.json\n",
      "tokenizer_config_file tokenizer_config.json\n",
      "본 발명에 따르면, 폴리로탁산 모노머의 우수한 기계 특성을 유지하면서, 생산성이 높고, 고품질의 재료를 얻을 수율로 제조할 수 있는 폴리로탁산 모노머를 제공할 수 있다., confidence: 0.3447664976119995\n",
      "본 발명에 따르면, 폴리로탁산 모노머의 우수한 기계 특성을 유지하면서, 생산성이 높고, 고품질의 재료를 제조할 수율로 제조할 수 있는 폴리로탁산 모노머를 제공할 수 있다., confidence: 0.19645027816295624\n",
      "본 발명에 따르면, 폴리로탁산 모노머의 우수한 기계 특성을 유지하면서, 생산성이 높고, 고품질의 재료를 제공할 수율로 제조할 수 있는 폴리로탁산 모노머를 제공할 수 있다., confidence: 0.06571029126644135\n",
      "본 발명에 따르면, 폴리로탁산 모노머의 우수한 기계 특성을 유지하면서, 생산성이 높고, 고품질의 재료를 형성할 수율로 제조할 수 있는 폴리로탁산 모노머를 제공할 수 있다., confidence: 0.04921877011656761\n",
      "본 발명에 따르면, 폴리로탁산 모노머의 우수한 기계 특성을 유지하면서, 생산성이 높고, 고품질의 재료를 사용할 수율로 제조할 수 있는 폴리로탁산 모노머를 제공할 수 있다., confidence: 0.023546047508716583\n",
      "폴리아미드 섬유 또는 폴리우레탄 섬유로부터 되는 섬유 ( x ) 와 폴리오레핀 ( polyolefin ) 수지와 포토 크로믹 재료를 함유 하는 섬유 하지만 서로 꼼 합쳐진 것인 스타킹용, confidence: 0.5708385109901428\n",
      "폴리아미드 섬유 또는 폴리우레탄 섬유로부터 되는 섬유 ( x ) 와 폴리오레핀 ( polyolefin ) 수지와 포토 크로믹 재료를 함유 하는 것 하지만 서로 꼼 합쳐진 것인 스타킹용, confidence: 0.015200018882751465\n",
      "폴리아미드 섬유 또는 폴리우레탄 섬유로부터 되는 섬유 ( x ) 와 폴리오레핀 ( polyolefin ) 수지와 포토 크로믹 재료를 함유 하는 매트릭스 하지만 서로 꼼 합쳐진 것인 스타킹용, confidence: 0.015185856260359287\n",
      "폴리아미드 섬유 또는 폴리우레탄 섬유로부터 되는 섬유 ( x ) 와 폴리오레핀 ( polyolefin ) 수지와 포토 크로믹 재료를 함유 하는 적층체 하지만 서로 꼼 합쳐진 것인 스타킹용, confidence: 0.012024755589663982\n",
      "폴리아미드 섬유 또는 폴리우레탄 섬유로부터 되는 섬유 ( x ) 와 폴리오레핀 ( polyolefin ) 수지와 포토 크로믹 재료를 함유 하는 것으로 하지만 서로 꼼 합쳐진 것인 스타킹용, confidence: 0.01172130461782217\n",
      "본 발명의 칼라표시장치용 광선택 흡광제, 이를 포함하는 코팅제 및 상기 코팅제로 제조된 필터를 제공한다. 상기 광선택 흡광제는 테트라아자포피린 유도체의 이합체를 포함한다, confidence: 0.5857702493667603\n",
      "본 발명은 칼라표시장치용 광선택 흡광제, 이를 포함하는 코팅제 및 상기 코팅제로 제조된 필터를 제공한다. 상기 광선택 흡광제는 테트라아자포피린 유도체의 이합체를 포함한다, confidence: 0.3588508665561676\n",
      "본 출원은 칼라표시장치용 광선택 흡광제, 이를 포함하는 코팅제 및 상기 코팅제로 제조된 필터를 제공한다. 상기 광선택 흡광제는 테트라아자포피린 유도체의 이합체를 포함한다, confidence: 0.006721008103340864\n",
      "본 출원의 칼라표시장치용 광선택 흡광제, 이를 포함하는 코팅제 및 상기 코팅제로 제조된 필터를 제공한다. 상기 광선택 흡광제는 테트라아자포피린 유도체의 이합체를 포함한다, confidence: 0.006394286639988422\n",
      "본 발명에 칼라표시장치용 광선택 흡광제, 이를 포함하는 코팅제 및 상기 코팅제로 제조된 필터를 제공한다. 상기 광선택 흡광제는 테트라아자포피린 유도체의 이합체를 포함한다, confidence: 0.00485991220921278\n",
      "상기한 목적을 달성하기 위하여 본 발명은 나노 세공의 다공성 육방정계의 실리카 분체내의 실리콘 일부가 전이금속으로, 나노 세공내에 금속 산화물이 나노 크기로 담지된 복합분, confidence: 0.12623374164104462\n",
      "상기한 목적을 달성하기 위하여 본 발명은 나노 세공의 다공성 육방정계의 실리카 분체내의 실리콘 일부가 전이금속으로 이루어진 나노 세공내에 금속 산화물이 나노 크기로 담지된 복합분, confidence: 0.03193998336791992\n",
      "상기한 목적을 달성하기 위하여 본 발명은 나노 세공의 다공성 육방정계의 실리카 분체내의 실리콘 일부가 전이금속으로 하는 나노 세공내에 금속 산화물이 나노 크기로 담지된 복합분, confidence: 0.030975958332419395\n",
      "상기한 목적을 달성하기 위하여 본 발명은 나노 세공의 다공성 육방정계의 실리카 분체내의 실리콘 일부가 전이금속으로 구성되는 나노 세공내에 금속 산화물이 나노 크기로 담지된 복합분, confidence: 0.02893143706023693\n",
      "상기한 목적을 달성하기 위하여 본 발명은 나노 세공의 다공성 육방정계의 실리카 분체내의 실리콘 일부가 전이금속으로 금속 나노 세공내에 금속 산화물이 나노 크기로 담지된 복합분, confidence: 0.024001706391572952\n"
     ]
    }
   ],
   "source": [
    "pred_result = []\n",
    "for path in model_path:\n",
    "    model, tokenizer = model_load(path)\n",
    "    fill_mask = pipeline(\"fill-mask\", model=model, tokenizer=tokenizer)\n",
    "    for example in masked_sample:\n",
    "        for prediction in fill_mask(example):\n",
    "#             print(f\"{prediction['sequence']}, confidence: {prediction['score']}\")\n",
    "            pred_result.append([path[1], prediction['sequence'], prediction['score']])\n",
    "            \n",
    "#     print(\"=\"*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "831c5177",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_result = pd.DataFrame(np.array(pred_result), columns=['chkpoints', 'mask_pred', 'proba'])\n",
    "pred_result['mask_pred'].str.normalize('NFKC')\n",
    "pred_result.to_csv('data/masklm_pred_result.csv', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fed4c6a8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bert_pretrain",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
